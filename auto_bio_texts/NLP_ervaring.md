James has been busy the last 6 months working on a number of NLP projects. 
- An app called "grbr" which pulls information from the google search API based on a query, summarizes the text, gives it a relevancy score compared to the query and provides a link to the initial website from which the text was taken. The NLP packages/ models used here were: transformers, sentence_transformers, BERT, langchain, pytorch.
- An app called "ba-smrzr" which pulls data from the google alerts API periodically about a specific topic, summarizes the text, gives it a relevancy score compared to the query and provides a link to the initial website from which the text was taken. This data is then stored in a postgres database, and an email is sent to end users containing relevant information about the topics they want to track in the market. The NLP packages/ models used here were: transformers, sentence_transformers, BERT, openai (davinci and GPT-3.5).
- To better understand how different topic extraction methods worked he did a deep dive comparison between LDA, LSA, NMF, and BERTopic in order to extract user experiences when using a service from different competitors. The NLP packages/ models used here were: spacy, gensim, sklearn, bertopic and nltk.
James is happy to demo any of the above projects upon request. 
